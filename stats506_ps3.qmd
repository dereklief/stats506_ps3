---
title: "stats506_ps3"
format: html
editor: visual
---

## **Problem 1 - Vision**

This problem will require you to do things in Stata we have not covered. Use the Stata help, or online resources, to figure out the appropriate command(s). Use citation as necessary.

a.  Download the file VIX_D from [this location](http://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Examination&CycleBeginYear=2005), and determine how to read it into Stata. Then download the file DEMO_D from [this location](http://wwwn.cdc.gov/Nchs/Nhanes/Search/DataPage.aspx?Component=Demographics&CycleBeginYear=2005). Note that each page contains a link to a documentation file for that data set. Merge the two files to create a single Stata dataset, using the **SEQN** variable for merging. Keep only records which matched. Print our your total sample size, showing that it is now 6,980.

    First, the do-file input:

    ``` stata
    import sasxport5 "C:\Users\dlief\Desktop\VIX_D.XPT", clear
    sort seqn
    save "C:\Users\dlief\Desktop\ps3_data_1", replace

    import sasxport5 "C:\Users\dlief\Desktop\DEMO_D.XPT", clear
    sort seqn
    save "C:\Users\dlief\Desktop\ps3_data_2", replace

    merge 1:1 seqn using "C:\Users\dlief\Desktop\ps3_data_1.dta"
    keep if _merge==3
    save "C:\Users\dlief\Desktop\ps3_merged_data", replace

    count
    ```

    Second, the output:

    ``` stata
    . do "C:\Users\dlief\Documents\ps3.do"

    . import sasxport5 "C:\Users\dlief\Desktop\VIX_D.XPT", clear

    . sort seqn

    . save "C:\Users\dlief\Desktop\ps3_data_1", replace
    file C:\Users\dlief\Desktop\ps3_data_1.dta saved

    . 
    . import sasxport5 "C:\Users\dlief\Desktop\DEMO_D.XPT", clear

    . sort seqn

    . save "C:\Users\dlief\Desktop\ps3_data_2", replace
    file C:\Users\dlief\Desktop\ps3_data_2.dta saved

    . 
    . merge 1:1 seqn using "C:\Users\dlief\Desktop\ps3_data_1.dta"

        Result                      Number of obs
        -----------------------------------------
        Not matched                         3,368
            from master                     3,368  (_merge==1)
            from using                          0  (_merge==2)

        Matched                             6,980  (_merge==3)
        -----------------------------------------

    . keep if _merge==3
    (3,368 observations deleted)

    . save "C:\Users\dlief\Desktop\ps3_merged_data", replace
    file C:\Users\dlief\Desktop\ps3_merged_data.dta saved

    . 
    . count
      6,980

    . 
    end of do-file

    . 
    ```

b.  Without fitting any models, estimate the proportion of respondents within each 10-year age bracket (e.g. 0-9, 10-19, 20-29, etc) who wear glasses/contact lenses for distance vision. Produce a nice table with the results.

    (Hint: One approach might be to try and find a way to produce this table with a single command. Another might be to estimate each proportion separately and then combine the results somehow. Yet another approach might be to manually do the calculations in Mata. Or any other approach that produces a single nice table.)

    First, the do-file input:

    ``` stata
    egen year_cat = cut(ridageyr), at(10,20,30,40,50,60,70,80,90)
    tabstat ridageyr, by(year_cat) stats(min max count)

    gen year_cat_str = "10 to 19" if year_cat == 10
    replace year_cat_str = "20 to 29" if year_cat == 20
    replace year_cat_str = "30 to 39" if year_cat == 30
    replace year_cat_str = "40 to 49" if year_cat == 40
    replace year_cat_str = "50 to 59" if year_cat == 50
    replace year_cat_str = "60 to 69" if year_cat == 60
    replace year_cat_str = "70 to 79" if year_cat == 70
    replace year_cat_str = "80 to 89" if year_cat == 80

    gen viq220_cat = "Yes" if viq220 == 1
    replace viq220_cat = "No" if viq220 == 2
    replace viq220_cat = "DK" if viq220 == 9

    tabulate year_cat_str viq220_cat, row
    ```

Second, the do-file output (I note that "DK" represents "don't know"):

``` stata
. egen year_cat = cut(ridageyr), at(10,20,30,40,50,60,70,80,90)

. tabstat ridageyr, by(year_cat) stats(min max count)

Summary for variables: ridageyr
Group variable: year_cat 

year_cat |       Min       Max         N
---------+------------------------------
      10 |        12        19      2207
      20 |        20        29      1021
      30 |        30        39       818
      40 |        40        49       815
      50 |        50        59       631
      60 |        60        69       661
      70 |        70        79       469
      80 |        80        85       358
---------+------------------------------
   Total |        12        85      6980
----------------------------------------

. 
. gen year_cat_str = "10 to 19" if year_cat == 10
(4,773 missing values generated)

. replace year_cat_str = "20 to 29" if year_cat == 20
(1,021 real changes made)

. replace year_cat_str = "30 to 39" if year_cat == 30
(818 real changes made)

. replace year_cat_str = "40 to 49" if year_cat == 40
(815 real changes made)

. replace year_cat_str = "50 to 59" if year_cat == 50
(631 real changes made)

. replace year_cat_str = "60 to 69" if year_cat == 60
(661 real changes made)

. replace year_cat_str = "70 to 79" if year_cat == 70
(469 real changes made)

. replace year_cat_str = "80 to 89" if year_cat == 80
(358 real changes made)

. 
. gen viq220_cat = "Yes" if viq220 == 1
(4,215 missing values generated)

. replace viq220_cat = "No" if viq220 == 2
(3,780 real changes made)

. replace viq220_cat = "DK" if viq220 == 9
(2 real changes made)

. 
. tabulate year_cat_str viq220_cat, row

+----------------+
| Key            |
|----------------|
|   frequency    |
| row percentage |
+----------------+

year_cat_s |            viq220_cat
        tr |        DK         No        Yes |     Total
-----------+---------------------------------+----------
  10 to 19 |         0      1,418        670 |     2,088 
           |      0.00      67.91      32.09 |    100.00 
-----------+---------------------------------+----------
  20 to 29 |         2        631        306 |       939 
           |      0.21      67.20      32.59 |    100.00 
-----------+---------------------------------+----------
  30 to 39 |         0        481        269 |       750 
           |      0.00      64.13      35.87 |    100.00 
-----------+---------------------------------+----------
  40 to 49 |         0        487        286 |       773 
           |      0.00      63.00      37.00 |    100.00 
-----------+---------------------------------+----------
  50 to 59 |         0        274        335 |       609 
           |      0.00      44.99      55.01 |    100.00 
-----------+---------------------------------+----------
  60 to 69 |         0        238        392 |       630 
           |      0.00      37.78      62.22 |    100.00 
-----------+---------------------------------+----------
  70 to 79 |         0        148        299 |       447 
           |      0.00      33.11      66.89 |    100.00 
-----------+---------------------------------+----------
  80 to 89 |         0        103        208 |       311 
           |      0.00      33.12      66.88 |    100.00 
-----------+---------------------------------+----------
     Total |         2      3,780      2,765 |     6,547 
           |      0.03      57.74      42.23 |    100.00 

. 
end of do-file
```

I note that the $2,765$ number I get above (for total wearers of contacts/glasses across the age groups) aligns with the number provided in the documentation here: <https://wwwn.cdc.gov/Nchs/Nhanes/2005-2006/VIX_D.htm#VIQ220>, which represents a quick check.

c\. Fit three logistic regression models predicting whether a respondent wears glasses/contact lenses for distance vision. Predictors:

1.  age

2.  age, race, gender

3.  age, race, gender, Poverty Income ratio

Produce a table presenting the estimated odds ratios for the coefficients in each model, along with the sample size for the model, the pseudo-$R^2$ , and AIC values.

First, I note that I eliminated observations that indicated they did not know whether they wore contacts or glasses OR they were missing. In short, I was left with $6,545$ observations of people who either had contacts/glasses or did not. This is the data I used to estimate my models. For the first, model, my do file was as follows (this includes the manipulation to get the data just including those who have contacts/glasses or do not):

``` stata
keep if (viq220 <= 2) 
gen viq220_log = 0 if viq220==2
replace viq220_log = 1 if viq220==1

logit viq220_log ridageyr
estat ic
```

And the output:

``` stata
. keep if (viq220 <= 2) 
(435 observations deleted)

. gen viq220_log = 0 if viq220==2
(2,765 missing values generated)

. replace viq220_log = 1 if viq220==1
(2,765 real changes made)

. logit viq220_log ridageyr

Iteration 0:  Log likelihood = -4457.6265  
Iteration 1:  Log likelihood = -4236.2351  
Iteration 2:  Log likelihood = -4235.9433  
Iteration 3:  Log likelihood = -4235.9433  

Logistic regression                                     Number of obs =  6,545
                                                        LR chi2(1)    = 443.37
                                                        Prob > chi2   = 0.0000
Log likelihood = -4235.9433                             Pseudo R2     = 0.0497

------------------------------------------------------------------------------
  viq220_log | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    ridageyr |   .0246729   .0012055    20.47   0.000     .0223101    .0270357
       _cons |   -1.26097   .0534482   -23.59   0.000    -1.365727   -1.156213
------------------------------------------------------------------------------

. estat ic

Akaike's information criterion and Bayesian information criterion

-----------------------------------------------------------------------------
       Model |          N   ll(null)  ll(model)      df        AIC        BIC
-------------+---------------------------------------------------------------
           . |      6,545  -4457.627  -4235.943       2   8475.887    8489.46
-----------------------------------------------------------------------------
Note: BIC uses N = number of observations. See [R] IC note.

. 
end of do-file
```

For the second model, I made female == 0 as opposed to 2 (this is just more intuitive to me). Then I ran the model. My do-file input is below:

``` stata
gen riagendr_log = 0 if riagendr==2
replace riagendr_log = 1 if riagendr==1

logit viq220_log c.ridageyr i.riagendr_log
estat ic
```

And the output:

``` stata
. gen riagendr_log = 0 if riagendr==2
(3,195 missing values generated)

. replace riagendr_log = 1 if riagendr==1
(3,195 real changes made)

. logit viq220_log c.ridageyr i.riagendr_log

Iteration 0:  Log likelihood = -4457.6265  
Iteration 1:  Log likelihood = -4191.5745  
Iteration 2:  Log likelihood = -4190.7367  
Iteration 3:  Log likelihood = -4190.7366  

Logistic regression                                     Number of obs =  6,545
                                                        LR chi2(2)    = 533.78
                                                        Prob > chi2   = 0.0000
Log likelihood = -4190.7366                             Pseudo R2     = 0.0599

--------------------------------------------------------------------------------
    viq220_log | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
---------------+----------------------------------------------------------------
      ridageyr |   .0254386   .0012207    20.84   0.000     .0230462    .0278311
1.riagendr_log |   -.496538   .0525275    -9.45   0.000      -.59949   -.3935861
         _cons |  -1.052571    .057459   -18.32   0.000    -1.165188   -.9399532
--------------------------------------------------------------------------------

. estat ic

Akaike's information criterion and Bayesian information criterion

-----------------------------------------------------------------------------
       Model |          N   ll(null)  ll(model)      df        AIC        BIC
-------------+---------------------------------------------------------------
           . |      6,545  -4457.627  -4190.737       3   8387.473   8407.832
-----------------------------------------------------------------------------
Note: BIC uses N = number of observations. See [R] IC note.

. 
end of do-file
```

And lastly, the do-file for the third model:

``` stata
logit viq220_log c.ridageyr i.riagendr_log c.indfmpir
estat ic
```

And the output:

``` stata
. logit viq220_log c.ridageyr i.riagendr_log c.indfmpir

Iteration 0:  Log likelihood = -4259.5533  
Iteration 1:  Log likelihood = -3974.5323  
Iteration 2:  Log likelihood = -3973.1801  
Iteration 3:  Log likelihood = -3973.1798  

Logistic regression                                     Number of obs =  6,247
                                                        LR chi2(3)    = 572.75
                                                        Prob > chi2   = 0.0000
Log likelihood = -3973.1798                             Pseudo R2     = 0.0672

--------------------------------------------------------------------------------
    viq220_log | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
---------------+----------------------------------------------------------------
      ridageyr |   .0239921     .00126    19.04   0.000     .0215224    .0264617
1.riagendr_log |  -.5190046   .0540545    -9.60   0.000    -.6249495   -.4130597
      indfmpir |   .1519579   .0168443     9.02   0.000     .1189436    .1849722
         _cons |  -1.362932   .0712438   -19.13   0.000    -1.502567   -1.223296
--------------------------------------------------------------------------------

. estat ic

Akaike's information criterion and Bayesian information criterion

-----------------------------------------------------------------------------
       Model |          N   ll(null)  ll(model)      df        AIC        BIC
-------------+---------------------------------------------------------------
           . |      6,247  -4259.553   -3973.18       4    7954.36   7981.319
-----------------------------------------------------------------------------
Note: BIC uses N = number of observations. See [R] IC note.

. 
end of do-file
```

The assignment also asks us to produce a table presenting the estimated odds ratios for the coefficients in each model, along with the sample size for the model, the pseudo-$R^2$ and AIC values. To do this, I wrote the following do-file code:

``` stata
quietly logit viq220_log ridageyr
estimates store e1

quietly logit viq220_log c.ridageyr i.riagendr_log
estimates store e2

quietly logit viq220_log c.ridageyr i.riagendr_log c.indfmpir
estimates store e3

etable, column(index) estimates(e1 e2 e3) mstat(r2_p) mstat(aic) showstars showstarsnote note(DV=contacts_glasses)
```

And the output is as follows:

``` stata
. etable, column(index) estimates(e1 e2 e3) mstat(r2_p) mstat(aic) showstars show
> starsnote note(DV=contacts_glasses)

----------------------------------------------------------------------
                                           1          2          3    
----------------------------------------------------------------------
Age at Screening Adjudicated - Recode   0.025 **   0.025 **   0.024 **
                                      (0.001)    (0.001)    (0.001)   
riagendr_log                                                          
  1                                               -0.497 **  -0.519 **
                                                 (0.053)    (0.054)   
Family PIR                                                    0.152 **
                                                            (0.017)   
Intercept                              -1.261 **  -1.053 **  -1.363 **
                                      (0.053)    (0.057)    (0.071)   
Pseudo R-squared                         0.05       0.06       0.07   
AIC                                   8475.89    8387.47    7954.36   
----------------------------------------------------------------------
** p<.01, * p<.05
DV=contacts_glasses

. 
end of do-file
```

d\. From the third model from the previous part, discuss whether the *odds* of men and women being wears of glasess/contact lenses for distance vision differs. Test whether the *proportion* of wearers of glasses/contact lenses for distance vision differs between men and women. Include the results of the test and its interpretation.

We see that the coefficient on gender in the third model is $-0.519$ and that it is statistically significant at the $0.01$ level. What this means is that holding Family PIR and age at screening, being male yields a $0.519$ decrease in $log(p)$ , or \$log(p/1-p)\$. Now, $exp(-0.519) = 0.595$ which implies that the odds of wearing glasses/contacts for males is $0.595$ times that of females (i.e. less).

For the second part of this question, to test whether the $proportion$ of wearers of glasses/contacts for distance vision, differs between men and women, I conducted two simple t-tests (one assuming equal variance and the other assuming unequal variance). I note that the t-test works to test proportions here because I coded the glasses/contacts variable as $0$ (if they don't have) or $1$ if they do. In both cases, the t-tests show that the proportions are statistically significantly different between men and women, with men less likely to to wear contacts/glasses when compared to women (which aligns with the results from our logistic regression too). Below, I present the do-file input followed by the stata output:

``` stata
ttest viq220_log, by(riagendr_log)
ttest viq220_log, by(riagendr_log) unequal
```

And the output:

``` stata
. ttest viq220_log, by(riagendr_log)

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]
---------+--------------------------------------------------------------------
       0 |   3,350    .4728358    .0086272    .4993361    .4559207     .489751
       1 |   3,195    .3696401    .0085412    .4827828    .3528934    .3863868
---------+--------------------------------------------------------------------
Combined |   6,545    .4224599    .0061061    .4939887      .41049    .4344298
---------+--------------------------------------------------------------------
    diff |            .1031958    .0121497                .0793784    .1270132
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   8.4937
H0: diff = 0                                     Degrees of freedom =     6543

    Ha: diff < 0                 Ha: diff != 0                 Ha: diff > 0
 Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0000          Pr(T > t) = 0.0000

. ttest viq220_log, by(riagendr_log) unequal

Two-sample t test with unequal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]
---------+--------------------------------------------------------------------
       0 |   3,350    .4728358    .0086272    .4993361    .4559207     .489751
       1 |   3,195    .3696401    .0085412    .4827828    .3528934    .3863868
---------+--------------------------------------------------------------------
Combined |   6,545    .4224599    .0061061    .4939887      .41049    .4344298
---------+--------------------------------------------------------------------
    diff |            .1031958      .01214                .0793974    .1269942
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   8.5005
H0: diff = 0                     Satterthwaite's degrees of freedom =  6541.78

    Ha: diff < 0                 Ha: diff != 0                 Ha: diff > 0
 Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0000          Pr(T > t) = 0.0000

. 
end of do-file
```

## **Problem 2 - Sakila**

Load the \"sakila\" database discussed in class into SQLite. It can be downloaded from <https://github.com/bradleygrant/sakila-sqlite3>.

```{r}
library(RSQLite)
library(DBI)
sakila <- dbConnect(RSQLite::SQLite(), "/Users/dereklief/Desktop/SQLite/sakila_master.db")
```

a.  Aside from English, what language is most common for films? Answer this with a single SQL query.

The query below suggests that English is the only language used in the films (but I limit it to 20 to keep it from going to 4,581 - the number of films in the inventory):

```{r}
dbGetQuery(sakila, "SELECT i.film_id, i.inventory_id, f.title, l.name, l.language_id
                    FROM film as f
                    INNER JOIN inventory as i ON i.film_id = f.film_id
                    INNER JOIN language as l ON f.language_id = l.language_id
                    GROUP BY i.inventory_id
                    limit 20")

```

So if I had to use one line of code, I would use the below, which shows us that indeed, across three variables, English is the only language used.

```{r}
dbGetQuery(sakila, "SELECT COUNT(DISTINCT l.name), COUNT(DISTINCT l.language_id), COUNT(DISTINCT f.language_id)
                    FROM film as f
                    INNER JOIN inventory as i ON i.film_id = f.film_id
                    INNER JOIN language as l ON f.language_id = l.language_id")
```

For each of the following question, solve them in two ways: First, use SQL query or queries to extract the appropriate table(s), then use regular R to answer the question. Second, use a single SQL query to answer the question.

b.  What genre of movie is the most common in the data, and how many movies are of this genre?

First, let's use SQL query (or queries) and R to do this.

```{r}
df_1 <- dbGetQuery(sakila, "SELECT i.inventory_id, f.title, c.name
                    FROM film as f
                    INNER JOIN inventory as i ON i.film_id = f.film_id
                    INNER JOIN film_category as fc ON fc.film_id = f.film_id
                    INNER JOIN category as c ON c.category_id = fc.category_id")
table(df_1$name)
remove(df_1)
```

This R function (combined with the SQL query) shows us that "Sports" is the most common category of film with $344$.

For a single SQL query, I would do the following:

```{r}
dbGetQuery(sakila, "SELECT c.name, COUNT(*)
                    FROM film as f
                    INNER JOIN inventory as i ON i.film_id = f.film_id
                    INNER JOIN film_category as fc ON fc.film_id = f.film_id
                    INNER JOIN category as c ON c.category_id = fc.category_id
                    GROUP BY c.name")

```

And we can see just by eye that "Sports" has the greatest number of entries with $344$.

c\. Identify which country or countries have exactly 9 customers. Answer this with a single SQL query.

First, let's do this with R followed by SQL:

```{r}
library(janitor)
df_2 <- dbGetQuery(sakila, "SELECT cou.country_id, cou.country, cust.customer_id
                    FROM city as cit
                    INNER JOIN country as cou ON cou.country_id = cit.country_id
                    INNER JOIN address as a ON a.city_id = cit.city_id
                    INNER JOIN customer as cust ON cust.address_id = a.address_id")

library(dplyr)
df_3 <- df_2 %>%count(country)
df_3[df_3$n == 9,]
remove(df_2)
remove(df_3)
```

We see that just the United Kingdom has nine customers. Now let's do this with SQL.

```{r}
dbGetQuery(sakila, "SELECT cou.country, COUNT(*)
                    FROM city as cit
                    INNER JOIN country as cou ON cou.country_id = cit.country_id
                    INNER JOIN address as a ON a.city_id = cit.city_id
                    INNER JOIN customer as cust ON cust.address_id = a.address_id
                    GROUP BY cou.country
                    HAVING COUNT(*)==9")
```

And we see the same result above.

## **Problem 3 - US Records**

Download the \"US - 500 Records\" data from <https://www.briandunning.com/sample-data/> and import it into R. This is entirely fake data - use it to answer the following questions.

```{r}
us500 <- read.csv("/Users/dereklief/Desktop/MAIN FOLDER/Classes and Other/STATS 506/PS 3/stats506_ps3/us-500.csv", header = TRUE)
```

a.  What proportion of email addresses are hosted at a domain with TLD \".net\"? (E.g. in the email, \"angrycat\@freemail.org\", \"freemail.org\" is the domain, with TLD (top-level domain) \".org\".)

```{r}
emails <- c(us500$email)
emails_net <- emails[grepl(".*\\.[n][e][t]", emails)]
length(emails_net) / nrow(us500)
```

$0.14$ of the emails are hosted a domain with TLD ".net".

b\. What proportion of email addresses have at least one non alphanumeric character in them? (Excluding the required \"`@`\" and \"`.`\" found in every email address.)

```{r}

email_un <- lapply(emails, FUN = function(x) strsplit(x, split="@")[[1]][1])
#(NOTE: I used help from this for extracting the first element: https://stackoverflow.com/questions/33683862/first-entry-from-string-split)
email_un <- paste(unlist(email_un))
emails_na <- email_un[grepl("[^a-zA-Z0-9]+", email_un)]
length(emails_na) / nrow(us500)
```

$0.506$ of the email addresses have at least one non alphanumeric character in them.

c\.
